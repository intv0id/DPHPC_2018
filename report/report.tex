% IEEE standard conference template; to be used with:
%   spconf.sty  - LaTeX style file, and
%   IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------

\documentclass[letterpaper]{article}
\usepackage{spconf,amsmath,amssymb,graphicx}

% Example definitions.
% --------------------
% nice symbols for real and complex numbers
\newcommand{\R}[0]{\mathbb{R}}
\newcommand{\C}[0]{\mathbb{C}}

% bold paragraph titles
\newcommand{\mypar}[1]{{\bf #1.}}

% Title.
% ------
\title{Minimum Spanning Tree: a parallel approach}


% For example:
% ------------
%\address{School\\
%		 Department\\
%		 Address}
%
% Two addresses (uncomment and modify for two-address case).
% ----------------------------------------------------------
\twoauthors
  {Th. Cambier, R. Dang-Nhu, Th. Dardinier}
  {
	Ecole Polytechnique\\
  	{\small Route de Saclay, 91128 Palaiseau Cedex, FRANCE}\\
  	ETH Z\"urich, D-INFK\\
	{\small Rämistrasse 101, 8092 Z\"rich, SWITZERLAND}
  }
  {C. Trassoudaine\sthanks{The fourth author performed the work while at ETH Z\"rich}}
  {
	  IMT Atlantique,\\
	  {\small 655 Avenue du Technopôle, 29280 Plouzané, FRANCE}\\
	  EURECOM, Data Science dpt.,\\
	  {\small 450 route des Chappes, 06410 Biot, FRANCE}
  }


\begin{document}
%\ninept
%
\maketitle
%


\begin{abstract}

ABSTRACT

\end{abstract}

\section{Introduction}\label{sec:intro}

Introduction

\mypar{Motivation} 

What are we doing and why / What is done in the paper

\mypar{Related work} 

Some references / what do they do /difference with us / make clear what our contribution is

\section{Background}\label{sec:background}

In this section, we define the Minimum Spanning Tree (MST) problem and introduce the algorithms we will use for experiments including a cost analysis.

\mypar{Minimum Spanning Tree problem}
A minimum spanning tree is a subset of the edges of a connected, edge-weighted undirected graph that connects all the vertices together, without any cycles and with the minimum possible total edge weight. That is, it is a spanning tree whose sum of edge weights is as small as possible. Here we consider only undirected and connected graphs and we present different algorithms to compute the minimum spanning tree over them. In the following, n is the number of vertices, m the number of edges in the graph and p the number of cores on which the parallel algorithms are run.

\mypar{MST sequential algorithms} The three main sequential algorithms to compute minimum spanning trees are Prim's, Kruskal's and Sollin's (also known as Borůvka's)  algorithms. All are greedy approaches :
\begin{itemize}
    \item Prim : we initialise a tree with a single random vertex and, at each step, we choose the vertex connected to the tree with the smallest-weighted edge and add it to the tree until all vertices are added.
    \item Kruskal : we sort the edges of the graph by increasing weight and, at each step, we add to the tree the smallest edge that does not create a cycle.
    \item Sollin : we initialise each vertex of the graph as a set and, at each step, we add the smallest-weighted edge from every set to another until the tree is formed.
\end{itemize}

We chose to implement Prim's algorithm with graphs represented as adjacency lists and to use a binary heap to keep the order of the vertices by the smallest edge-weight that connects them to any vertex in the partially constructed tree. With such a structure, Prim's algorithm computes a minimum spanning tree in $\mathcal{O}(mlogn)$.

Kruskal's algorithm relies on an union-find data structure which maintains a set for each connected component. If we want to add an edge with its extremities in different components, we need to merge the components because they are now connected. The sorting of the edges is done in $\mathcal{O}(mlog(m))$ sequentially and the adding of edges is done in $\mathcal{O}(m)$.

Sollin's algorithm takes $\mathcal{O}(log(n))$ iterations until it terminates because they are V components at the beginning and each iteration reduces the number of components by at least two. Therefore it runs in time $\mathcal{O}(mlog(n))$.

\mypar{MST parallel algorithms}  The first parallel MST algorithm we consider is a variant of Kruskal's algorithm named Filter Kruskal. The idea of this algorithm is to "filter out" some edges that are assumed not part of the MST to reduce sorting time. Firstly, the number of edges m is compared to a threshold under which we choose to compute the sequential Kruskal. Then, an edge is chosen as a pivot regarding weight to separate the edges in two weight categories (heavier and lighter edges). A first recursive call is made on the lighter edges. Before making the second recursive calls on the heavier ones, all heavy edges that are within a component of the current forest are removed (filtering step). To finish the algorithm, the results from both calls are merged to form the MST. For the cost analysis of the algorithm, we use $T(m)$ for the runtime of the algorithm with m edges. The choosing of the pivot can be done in $\mathcal{O}(1)$ by sampling 256 edges from the graph using OpenMP and taking the median thanks to Intel TBB (see experimental setup in Sec. \ref{sec:exp}). The partition of the edges as well as the filtering can both be done in $\mathcal{O}(\frac{m}{p})$ using the partition function from Intel Parallel STL. The first recursive call costs $T(\frac{m}{2})$ and the second one $\mathcal{O}(T(\frac{m}{2}))$ (and far less in practice) because edges have been removed. In the best case, the first recursive call is sufficient to compute the MST and we have $T(m) \leq  \mathcal{O}(\frac{m}{p}) + T(\frac{m}{2})) $ which gives $T(m) = \mathcal{O}(\frac{m}{p} + m) = \mathcal{O}(m)$. In the worst case, we have $T(m) \leq  \mathcal{O}(\frac{m}{p}) + 2T(\frac{m}{2})) $ which gives $T(m) = \mathcal{O}(\frac{mln(m)}{p} + m)$

\mypar{Input Sets}
The experiments have been performed on the three following input sets :

\begin{itemize}
    \item Erd\H{o}s-R\'{e}nyi (ER) random graphs where we specify the number of nodes of the graph and the probability of existence of a vertex between every pair of nodes. The probability is chosen greater than $\frac{ln(n)}{n}$ which is the threshold to have almost surely a connected graph.
    \item Preferential Attachment (PA) graphs where we specify the number of nodes of the graphs and the number of neighbours that a node attaches itself to when added in the graph. In order to have a connected graph, the graph is initialised with three connected vertices and new vertices are added one by one and connected to existing vertices with higher probability for the ones with higher degrees. This type of graph models better existing inputs from the real world such as representations of social network connections.  
    \item USA road networks from 9th Implementation DIMACS Challenge dataset which are real input sets from the road networks in various part of the USA. These graphs are connected and undirected.
\end{itemize}

\section{Method}\label{sec:method}


\section{Experimental Results}\label{sec:exp}


\mypar{Experimental setup} All experiments are run through the EULER cluster on an Hewlett-Packard XL230k Gen10 equipped with two 18-core Intel Xeon Gold (6150 processors, 2.7-3.7 GHz) and 192 GB of DDR4 memory clocked at 2666 MHz. We are using C++11 with GCC v4.9.2, CMake v3.3 and OpenMPI v1.6.5. We also use the following dependencies :
\begin{itemize}
    \item OpenMP which is an API that supports shared memory multiprocessing programming in C++.
    \item Threading Building Blocks (TBB) to write parallel C++ programs that take full advantage of multi-core performance.
    \item Parallel STL which offers a portable implementation of threaded and vectorized execution of standard C++ algorithms, optimised and validated for Intel(R) 64 processors.
\end{itemize}

\mypar{Benchmarks} 
benchmarks (input sizes)

\mypar{Baselines} We compare the results of our algorithms to those of the Parallel Boost Graph Library (PBGL) which is an extension of the BGL for distributed computing.

\mypar{Results}
classes of experiments answering to questions
compare code to external benchmarks.

\section{Conclusions}

What we did / why important

important results

next steps




% References should be produced using the bibtex program from suitable
% BiBTeX files (here: bibl_conf). The IEEEbib.bst bibliography
% style file from IEEE produces unsorted bibliography list.
% -------------------------------------------------------------------------
\bibliographystyle{IEEEbib}
\bibliography{bibl_conf}

\end{document}


